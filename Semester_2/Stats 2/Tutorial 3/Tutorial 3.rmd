---
title: "Tutorial 3"
author: "Jasper Gross"
output:
  html_document:
    df_print: paged
    theme: cosmo
---
<style>
body {text-align: justify}
</style>
---

# Problem 1

The random sample $\{{X}_i, i:1\to n\}$ is drawn from a exponential distribution with pdf $f(x,\theta) = \frac{1}{\theta}\exp\left(-\frac{x}{\theta}\right)$. The following statistics are considered as estimators for $\theta$:
\[
T_1 = \frac{1}{n}\sum_{i=1}^n X_i \quad \mbox{and}\quad T_2 =\Bigg[\frac{1}{2n}\sum_{i=1}^n  X_i^2\Bigg]^{1/2}\,.
\]

## a)
Write a function for each of the two estimators. The single argument should be a vector.

```{r warning=FALSE, error=TRUE}
T_1 = function(???){
  ???
}

T_2 = function(???){
  ???
}
```

## b)
Now write two functions. The first one should compute the bias of a given statistical quantity. The second one should compute the MSE of that statistial quantity.
The Bias and MSE can be defined as \[Bias = \frac{1}{n}\sum_{i=1}^n \hat{Y}_i - Y \hspace{1cm} \text{and} \hspace{1cm}  MSE = \frac{1}{n}\sum_{i=1}^n (\hat{Y}_i - Y)^2,\] where Y is the true value.

```{r warning=FALSE, error=TRUE}
bias = function(???){
  ???
}

MSE = function(???){
  ???
}
```

## c)
Draw  random numbers and estimate $\theta$ (the mean) with the first estimator. Repeat this to calculate the MSE (for the first estimator). Compare this result to the MSE decomposition, i.e. $MSE = Bias^2 + Variance$. Does the decomposition hold?

```{r warning=FALSE, error=TRUE}
# Parameters
n     = ???   # sample size of RN~Exp(theta)
N_MC  = ???   # Repetitions of the simualtion
theta = ???   # true parameter value
seed  = ???   # seed of your choice

# Estimate the mean
set.seed(seed)
sample = ???

# Compute and compare the MSE formulas
MSE_1 = ???
MSE_2 = ??? 

abs(MSE_1 - MSE_2)

# Answer here
# ???
```

## d)
Compute samples of biases for $T_1$ and $T_2$. Then plot their empirical densities and indicate their means (use two figures!). Are these estimators biased?

```{r warning=FALSE, error=TRUE, fig.align='center'}
# Added parameter
N_MC_2 = 1000  # Repetitions of the 2nd simulation (basically the sample size)

# Compute the samples 
set.seed(seed)
bias_t1 = ???
set.seed(seed)
bias_t2 = ???

# Plot 1
hist(???, main = 'emp. density of bias_t1')
abline(???, col = 'green', lwd = 2)
# Plot 2
hist(???, main = 'emp. density of bias_t2')
abline(???, col = 'red', lwd = 2)

# Answer here
# ???
```


## e)
Compute the variance for both estimators for different n and compare this to the CRLB using a meaningful figure. Add a legend to this figure. Do the estimators reach the CRLB? Can you verify the CRLB theorem? Hints: The CRLB for a exponentially distributed random variable is $CRLB = \frac{\theta^2}{n}$.

```{r warning=FALSE, error=TRUE, fig.align='center', fig.width = 10}
# Parameter
n = 1:100

# Vectors for later
vari_1 = replicate(length(n), NA)
vari_2 = replicate(length(n), NA)

# Simulation
for (i in n){
  set.seed(seed)
  vari_1[i] = ???
  set.seed(seed)
  vari_2[i] = ???
}

# Plot
plot(???, type = "l", col = "black", lwd = 2, ylab = "Variance", main = "CRLB")
lines(???, lwd = 2, col = "blue")
lines(???, lwd = 2, col = "green")
legend("topright", legend = ???, fill = ???)

# Answer here
# ???
```

## f)
Construct a third estimator $T_3$ for $\theta$ which has (theoretically) a smaller variance than the other two and implement this as a function in R.

```{r warning=FALSE, error=TRUE}
T_3 = function(???){
  ???
}
```

## g) 
Compute the MSE of all three estimators for different n and compare those in one single figure. Add a meaningful legend and a title to your plot.

```{r warning=FALSE, error=TRUE, fig.align='center', fig.width = 10}
# Parameter
n = 1:100

# Vectors for later
mse_1 = replicate(length(n), NA)
mse_2 = replicate(length(n), NA)
mse_3 = replicate(length(n), NA)

# Simulation
for (i in n){
  set.seed(seed)
  mse_1[i] = ???
  set.seed(seed)
  mse_2[i] = ???
  set.seed(seed)
  mse_3[i] = ???
}

# Plot
???
```

Based on your previous results argue why the MSE might be preferred to the variance as a loss function!
```{r warning=FALSE, error=TRUE}
# Answer here
```

